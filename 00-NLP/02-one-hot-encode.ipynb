{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **One-Hot Encoding(원-핫 인코딩)**\n",
    "\n",
    "`원-핫 인코딩`은 `원-핫` + `인코딩` 의 조합의 단어입니다.\n",
    "\n",
    "`원-핫 인코딩`이라는 단어 자체는 합성어이기 때문에 그 자체의 뜻은 알 수 없습니다.\n",
    "\n",
    "`원-핫`은 위키백과에서는 다음과 같이 정의를 하고 있습니다. [출처](https://en.wikipedia.org/wiki/One-hot)\n",
    "\n",
    "> In [digital circuits](https://en.wikipedia.org/wiki/Digital_circuits) and [machine learning](https://en.wikipedia.org/wiki/Machine_learning), a **one-hot** is a group of [bits](https://en.wikipedia.org/wiki/Bit) among which the legal combinations of values are only those with a single high bit and all the others low.\n",
    "> \n",
    "\n",
    "`'원-핫(one-hot)'`은 여러 비트 중 단 하나의 비트만 1이고 나머지는 모두 0인 유효한 조합을 나타내는 방식을 의미합니다.\n",
    "\n",
    "`인코딩`은 위키백과에서 다음과 같이 정의 하고 있습니다. [출처](https://ko.wikipedia.org/wiki/%EB%B6%80%ED%98%B8%ED%99%94)\n",
    "\n",
    "> [컴퓨터](https://ko.wikipedia.org/wiki/%EC%BB%B4%ED%93%A8%ED%84%B0)를 이용해 영상 **·** 이미지 **·** 소리 [데이터](https://ko.wikipedia.org/wiki/%EB%8D%B0%EC%9D%B4%ED%84%B0)를 생성할 때 데이터의 양을 줄이기 위해 **데이터를 코드화하고 압축하는 것**이다. [정보](https://ko.wikipedia.org/wiki/%EC%A0%95%EB%B3%B4)의 형태나 형식을 [표준화](https://ko.wikipedia.org/wiki/%ED%91%9C%EC%A4%80%ED%99%94), [보안](https://ko.wikipedia.org/wiki/%EB%B3%B4%EC%95%88), 처리 속도 향상, 저장 공간 절약 등을 위해서 다른 형태나 형식으로 [변환](https://ko.wikipedia.org/wiki/%EB%B3%80%ED%99%98)하는 것\n",
    "> \n",
    "\n",
    "`인코딩`은 데이터 압축을 위해서 사용되고 있습니다. 그리고 인코딩은 반드시 디코더를 통해서 원상복구가 가능해져야 한다는 특징도 가지고 있습니다.\n",
    "\n",
    "정리하자면, `원-핫 인코딩`은 `데이터를 원-핫 데이터 형태로 변형/압축하는 것` 이라고 할 수 있습니다.\n",
    "\n",
    "### 필요성\n",
    "\n",
    "- **범주형 데이터의 수치화** : 머신러닝 알고리즘은 숫자 데이터를 기반으로 동작하므로, 텍스트나 범주형 데이터를 숫자로 변환해야 합니다. 원핫 인코딩은 각 범주를 고유한 이진 벡터로 표현합니다.\n",
    "- **순서 정보 제거** : 범주형 데이터에 순서가 없는 경우(예: 색상, 국가), 원핫 인코딩은 각 범주를 독립적인 특성으로 처리하여 순서 정보를 제거합니다. 이는 모델이 잘못된 순서 정보를 학습하는 것을 방지합니다.\n",
    "- **특성 간의 독립성 보장** : 원핫 인코딩은 각 범주를 별도의 특성으로 분리하여, 특성 간의 독립성을 보장합니다. 이는 모델이 각 범주를 독립적으로 고려할 수 있게 합니다.\n",
    "- **알고리즘 호환성** : 선형 회귀, 로지스틱 회귀, 신경망 등 많은 알고리즘은 범주형 데이터를 직접 처리할 수 없으므로, 원핫 인코딩이 필요합니다.\n",
    "\n",
    "### 장점\n",
    "\n",
    "- **간단하고 직관적** : 범주형 데이터를 0과 1로 이루어진 벡터로 변환하므로 이해하기 쉽고 구현이 간단합니다.\n",
    "- **범주 간 독립성 보장** : 각 범주가 서로 독립적인 특성으로 처리되므로, 범주 간 순서나 관계가 없을 때 적합합니다.\n",
    "- **알고리즘 호환성** : 선형 모델, SVM, 신경망 등 다양한 머신러닝 알고리즘과 호환됩니다.\n",
    "\n",
    "### 단점\n",
    "\n",
    "- **차원 증가** : 범주의 수가 많을 경우 벡터의 차원이 급격히 증가하여 `계산 비용이 높아`지고 `메모리 사용량이 늘어`납니다.\n",
    "- **희소성 문제** : 대부분의 값이 0인 희소 행렬이 생성되어, 모델의 학습 효율성이 떨어질 수 있습니다.\n",
    "- **범주 간 관계 표현 불가** : 범주 간 순서나 관계가 있는 경우 이를 반영하지 못해 정보 손실이 발생할 수 있습니다.\n",
    "\n",
    "### 한계점\n",
    "\n",
    "- **차원의 증가** : 원-핫 인코딩은 각 범주를 고유한 이진 벡터로 표현하므로, 범주의 수가 많을수록 데이터의 차원이 급격히 증가합니다. 이는 계산 비용을 높이고, 메모리 사용량을 증가시킬 수 있습니다.\n",
    "- **희소성 문제** : 원-핫 인코딩은 대부분의 값이 0인 희소 행렬을 생성합니다. 이는 모델의 학습 효율성을 떨어뜨릴 수 있으며, 특히 딥러닝 모델에서 성능 저하를 일으킬 수 있습니다.\n",
    "- **의미적 유사성 무시** : 원-핫 인코딩은 모든 범주를 동등한 거리로 간주합니다. 예를 들어, \"개\"와 \"고양이\"가 \"자동차\"보다 서로 더 유사하다는 정보를 반영하지 못합니다. 이는 모델이 범주 간의 관계를 이해하는 데 어려움을 줄 수 있습니다.\n",
    "- **범주 간 관계 표현 불가** : 원-핫 인코딩은 범주 간의 관계를 전혀 표현하지 못합니다. 예를 들어, 순서가 있는 범주형 데이터(예: 낮음, 중간, 높음)의 경우, 원-핫 인코딩은 이러한 순서 정보를 잃어버립니다.\n",
    "- **새로운 범주 처리 어려움** : 학습 데이터에 없는 새로운 범주가 테스트 데이터에 나타날 경우, 원-핫 인코딩은 이를 처리할 수 없습니다. 이는 모델의 일반화 능력을 저하시킬 수 있습니다.\n",
    "\n",
    "### 동작 방식\n",
    "\n",
    "`원-핫 인코딩`은 세 가지 과정으로 동작합니다.\n",
    "\n",
    "1. 형태소 분리 : 단어 뭉치를 단어 배열로 분리하는 작업\n",
    "2. 정수 인코딩 : 단어 배열에서 각 단어에 고유한 정수를 부여합니다.\n",
    "3. 고유한 정수로 인덱스 생성 : 표현하고 싶은 단어의 고유한 정수를 인덱스로 간주하고 해당 위치에 1을 부여하고, 다른 단어의 인덱스의 위치에는 0을 부여합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "\n",
    "class OneHotEncoder:\n",
    "    def __init__(self):\n",
    "        self.categories = None  # 범주를 저장할 리스트\n",
    "        self.category_to_index = {}  # 범주를 인덱스로 매핑할 딕셔너리\n",
    "\n",
    "    def fit(self, texts: Union[str, List[str]]):\n",
    "        \"\"\"\n",
    "        데이터로부터 범주를 학습합니다.\n",
    "        \"\"\"\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "\n",
    "        self.categories = sorted(list(set(texts)))  # 고유한 범주 추출 및 정렬\n",
    "        self.category_to_index = {\n",
    "            category: idx for idx, category in enumerate(self.categories)\n",
    "        }\n",
    "\n",
    "    def transform(self, texts: Union[str, List[str]]) -> List[List[int]]:\n",
    "        \"\"\"\n",
    "        학습된 범주를 기반으로 데이터를 원-핫 인코딩합니다.\n",
    "        \"\"\"\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "\n",
    "        if self.categories is None:\n",
    "            raise ValueError(\"먼저 fit 메서드를 호출하여 범주를 학습해야 합니다.\")\n",
    "\n",
    "        encoded_data = []\n",
    "        for item in texts:\n",
    "            if item not in self.category_to_index:\n",
    "                raise ValueError(\n",
    "                    f\"새로운 범주 '{item}'가 발견되었습니다. fit 메서드로 학습된 범주만 처리할 수 있습니다.\"\n",
    "                )\n",
    "            one_hot_vector = [0] * len(self.categories)  # 0으로 초기화\n",
    "            index = self.category_to_index[item]  # 해당 범주의 인덱스 찾기\n",
    "            one_hot_vector[index] = 1  # 해당 위치를 1로 설정\n",
    "            encoded_data.append(one_hot_vector)\n",
    "        return encoded_data\n",
    "\n",
    "    def fit_transform(self, texts: List[str]) -> List[List[int]]:\n",
    "        \"\"\"\n",
    "        데이터로부터 범주를 학습하고, 동시에 원-핫 인코딩을 수행합니다.\n",
    "        \"\"\"\n",
    "        self.fit(texts)\n",
    "        return self.transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습된 범주: ['빨강', '초록', '파랑']\n",
      "학습 데이터 원-핫 인코딩 결과:\n",
      "[1, 0, 0]\n",
      "[0, 0, 1]\n",
      "[0, 1, 0]\n",
      "[0, 0, 1]\n",
      "[1, 0, 0]\n",
      "새로운 데이터 원-핫 인코딩 결과:\n",
      "[0, 0, 1]\n",
      "[0, 1, 0]\n",
      "[1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# 예시 데이터\n",
    "train_data = [\"빨강\", \"파랑\", \"초록\", \"파랑\", \"빨강\"]\n",
    "new_data = [\"파랑\", \"초록\", \"빨강\"]\n",
    "\n",
    "# 원-핫 인코더 생성 및 학습\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(train_data)\n",
    "\n",
    "# 학습된 범주 출력\n",
    "print(\"학습된 범주:\", encoder.categories)\n",
    "\n",
    "# 학습 데이터 변환\n",
    "encoded_train_data = encoder.transform(train_data)\n",
    "print(\"학습 데이터 원-핫 인코딩 결과:\")\n",
    "for item in encoded_train_data:\n",
    "    print(item)\n",
    "\n",
    "# 새로운 데이터 변환\n",
    "encoded_new_data = encoder.transform(new_data)\n",
    "print(\"새로운 데이터 원-핫 인코딩 결과:\")\n",
    "for item in encoded_new_data:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kss import Kss\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['나', '는', '팝콘', '을', '좋', '아', '해요']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_morphemes = Kss(\"tokenize\")\n",
    "text = \"나는 팝콘을 좋아해요\"\n",
    "tokens = split_morphemes(text)\n",
    "tokens = list(map(lambda x: x[0], tokens))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'나': 0, '는': 1, '팝콘': 2, '을': 3, '좋': 4, '아': 5, '해요': 6}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index = {word: idx for idx, word in enumerate(tokens)}\n",
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from kss import Kss\n",
    "from typing import List, Union\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "class KoreanOneHotEncoder:\n",
    "    def __init__(self):\n",
    "        self.one_hot_encoder = OneHotEncoder()\n",
    "        self.split_morphemes = Kss(\"tokenize\")\n",
    "    \n",
    "    @property\n",
    "    def categories(self):\n",
    "        return self.one_hot_encoder.categories\n",
    "    \n",
    "    def __transform(self, tokens: List[str]) -> List[List[int]]:\n",
    "        return self.one_hot_encoder.transform(tokens)\n",
    "\n",
    "    def tokenize(self, text: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        한국어 텍스트를 형태소로 분리합니다.\n",
    "        \"\"\"\n",
    "        tokens = self.split_morphemes(text)\n",
    "        tokens = list(map(lambda x: x[0], tokens))\n",
    "        return tokens\n",
    "\n",
    "    def fit(self, texts: Union[str, List[str]]):\n",
    "        \"\"\"\n",
    "        텍스트 데이터로부터 범주를 학습합니다.\n",
    "        \"\"\"\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "\n",
    "        all_tokens = []\n",
    "        for text in texts:\n",
    "            tokens = self.tokenize(text)\n",
    "            all_tokens.extend(tokens)\n",
    "        self.one_hot_encoder.fit(all_tokens)\n",
    "\n",
    "    def transform(self, texts: Union[str, List[str]]) -> List[List[List[int]]]:\n",
    "        \"\"\"\n",
    "        학습된 범주를 기반으로 텍스트 데이터를 원-핫 인코딩합니다.\n",
    "        \"\"\"\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "\n",
    "        encoded_texts = []\n",
    "        for text in texts:\n",
    "            tokens = self.tokenize(text)\n",
    "            encoded_tokens = self.__transform(tokens)\n",
    "            encoded_texts.append(encoded_tokens)\n",
    "        return encoded_texts\n",
    "\n",
    "    def fit_transform(self, texts: List[str]) -> List[List[int]]:\n",
    "        \"\"\"\n",
    "        텍스트 데이터로부터 범주를 학습하고, 동시에 원-핫 인코딩을 수행합니다.\n",
    "        \"\"\"\n",
    "        self.fit(texts)\n",
    "        return self.transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 예시\n",
    "texts = [\"나는 팝콘을 좋아해요\", \"오늘은 영화를 봤어요\", \"팝콘은 맛있어요\"]\n",
    "ko_encoder = KoreanOneHotEncoder()\n",
    "\n",
    "# fit_transform을 사용하여 학습 및 변환\n",
    "encoded_texts = ko_encoder.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나', '는', '를', '맛있', '봤', '아', '어요', '영화', '오늘', '은', '을', '좋', '팝콘', '해요']\n"
     ]
    }
   ],
   "source": [
    "print(ko_encoder.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합 : {'나': 0, '는': 1, '를': 2, '맛있': 3, '봤': 4, '아': 5, '어요': 6, '영화': 7, '오늘': 8, '은': 9, '을': 10, '좋': 11, '팝콘': 12, '해요': 13}\n"
     ]
    }
   ],
   "source": [
    "word_to_index = {word: index for index, word in enumerate(ko_encoder.categories)}\n",
    "print(\"단어 집합 :\", word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: 나는 팝콘을 좋아해요\n",
      "Vector 1: [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]\n",
      "\n",
      "Text 2: 오늘은 영화를 봤어요\n",
      "Vector 2: [[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]]\n",
      "\n",
      "Text 3: 팝콘은 맛있어요\n",
      "Vector 3: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, encoded_text in enumerate(encoded_texts):\n",
    "    print(f\"Text {i+1}: {texts[i]}\")\n",
    "    print(f\"Vector {i+1}: {encoded_text}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
